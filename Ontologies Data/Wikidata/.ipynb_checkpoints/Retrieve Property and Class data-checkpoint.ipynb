{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16921fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b085a",
   "metadata": {},
   "source": [
    "### The goal of this notebook is to retrieve the data from Wikidata however we do not have a direct access to a dump hence we will go through every possible property (until we do not have any results) to retrieve their labels, descriptions, ranges, domains and types.\n",
    "\n",
    "### However it should not be relaunched as it can take multiple hours to retrieve all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26120e79-983a-4021-b0fe-2483695fa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use this function to generate the possible property from wd:P_CPT to wd:P_CPT+step\n",
    "def generate_all_prop(cpt, step):\n",
    "    return \"wd:P\"+\" wd:P\".join([str(i) for i in range(cpt*step, (cpt+1)*step)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8d4be",
   "metadata": {},
   "source": [
    "# Properties\n",
    "\n",
    "## Label, description and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbdd3ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<Response [200]>\n",
      "1\n",
      "<Response [200]>\n",
      "2\n",
      "<Response [200]>\n",
      "3\n",
      "<Response [200]>\n",
      "4\n",
      "<Response [200]>\n",
      "5\n",
      "<Response [200]>\n",
      "6\n",
      "<Response [200]>\n",
      "7\n",
      "<Response [200]>\n",
      "8\n",
      "<Response [200]>\n",
      "9\n",
      "<Response [200]>\n",
      "10\n",
      "<Response [200]>\n",
      "11\n",
      "<Response [200]>\n",
      "12\n",
      "<Response [200]>\n",
      "13\n",
      "<Response [200]>\n",
      "14\n",
      "<Response [200]>\n",
      "15\n",
      "<Response [200]>\n",
      "16\n",
      "<Response [200]>\n",
      "17\n",
      "<Response [200]>\n",
      "18\n",
      "<Response [200]>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10276/1411547452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stop\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url = 'https://query.wikidata.org/sparql'\n",
    "res = []\n",
    "cpt = 0\n",
    "step = 250\n",
    "\n",
    "while True:\n",
    "    print(cpt)\n",
    "    query = \"\"\"\n",
    "    \n",
    "    SELECT DISTINCT ?property ?label ?description ?type\n",
    "    WHERE {\n",
    "      VALUES ?property {\"\"\"+generate_all_prop(cpt, step)+\"\"\"} \n",
    "      ?property rdfs:label ?label.\n",
    "      OPTIONAL{?property schema:description ?description}.\n",
    "      ?property wikibase:propertyType ?type.\n",
    "      FILTER(LANG(?description) = LANG(?label))\n",
    "      FILTER(LANG(?description) = \"en\")\n",
    "    }  LIMIT 10000\"\"\"\n",
    "    \n",
    "    cpt+=1\n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    print(r)\n",
    "    data = r.json()\n",
    "    if len(data[\"results\"][\"bindings\"]) > 1:\n",
    "        for line in data[\"results\"][\"bindings\"]:\n",
    "            prop = line[\"property\"][\"value\"]\n",
    "            label = line[\"label\"][\"value\"]\n",
    "            description = \"\"\n",
    "            if \"description\" in line:\n",
    "                description = line[\"description\"][\"value\"]\n",
    "            typ =  line[\"type\"][\"value\"]\n",
    "            res.append([prop, label, description, typ])\n",
    "    else:\n",
    "        print(\"stop\")\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831f3f9",
   "metadata": {},
   "source": [
    "## Now that we know which properties do exist we can only queries those from the variable props_possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_array = np.array(res)\n",
    "props_possible = pd.Series(list(set(res_array[:,0]))).map(lambda x: x.split(\"/\")[-1])\n",
    "props_possible = list(props_possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f7903",
   "metadata": {},
   "source": [
    "## Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7131f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://query.wikidata.org/sparql'\n",
    "res_range = []\n",
    "step = 250\n",
    "\n",
    "for i in range(0,len(props_possible), step):\n",
    "    print(i)\n",
    "    query = \"\"\"\n",
    "    \n",
    "    SELECT DISTINCT ?property ?range\n",
    "    WHERE {\n",
    "      VALUES ?property { wd:\"\"\"+\" wd:\".join(props_possible[i:i+step])+\"\"\" } \n",
    "      ?property p:P2302 ?statement.\n",
    "      ?statement ps:P2302 wd:Q21510865.\n",
    "      ?statement pq:P2308 ?range\n",
    "    }  LIMIT 10000\"\"\"\n",
    "    \n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    print(r)\n",
    "    data = r.json()\n",
    "    if len(data[\"results\"][\"bindings\"]) > 1:\n",
    "        for line in data[\"results\"][\"bindings\"]:\n",
    "            prop = line[\"property\"][\"value\"]\n",
    "            rang = line[\"range\"][\"value\"]\n",
    "            res_range.append([prop, rang])\n",
    "    else:\n",
    "        print(\"Got nothing\")\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ecf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73baf1fc",
   "metadata": {},
   "source": [
    "## Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e755d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://query.wikidata.org/sparql'\n",
    "res_domain = []\n",
    "step = 250\n",
    "\n",
    "for i in range(0,len(props_possible), step):\n",
    "    print(i)\n",
    "    query = \"\"\"\n",
    "    \n",
    "    SELECT DISTINCT ?property ?domain\n",
    "    WHERE {\n",
    "      VALUES ?property { wd:\"\"\"+\" wd:\".join(props_possible[i:i+step])+\"\"\" } \n",
    "      ?property p:P2302 ?v.\n",
    "      ?v ps:P2302 wd:Q21503250.\n",
    "      ?v pq:P2308 ?domain\n",
    "    }  LIMIT 10000\"\"\"\n",
    "    \n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    print(r)\n",
    "    data = r.json()\n",
    "    if len(data[\"results\"][\"bindings\"]) > 1:\n",
    "        for line in data[\"results\"][\"bindings\"]:\n",
    "            prop = line[\"property\"][\"value\"]\n",
    "            domain = line[\"domain\"][\"value\"]\n",
    "            res_domain.append([prop, domain])\n",
    "    else:\n",
    "        print(\"Got nothing\")\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420600d5",
   "metadata": {},
   "source": [
    "## We merge the data into a single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_prop = {}\n",
    "\n",
    "for line in res_range:\n",
    "#     print(line)\n",
    "    if line[0] in dic_prop:\n",
    "        dic_prop[line[0]][0].append(line[1])\n",
    "    else:\n",
    "        dic_prop[line[0]] = ([line[1]], [])\n",
    "        \n",
    "for line in res_domain:\n",
    "#     print(line)\n",
    "    if line[0] in dic_prop:\n",
    "        dic_prop[line[0]][1].append(line[1])\n",
    "    else:\n",
    "        dic_prop[line[0]] = ([], [line[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96260106",
   "metadata": {},
   "source": [
    "## We write the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"wikidata_P_describe.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "prefixes = [\"http://www.wikidata.org/prop/\", \"http://www.wikidata.org/prop/direct/\", \"http://www.wikidata.org/prop/direct-normalized/\", \"http://www.wikidata.org/prop/statement/\", \"http://www.wikidata.org/prop/statement/value/\", \"http://www.wikidata.org/prop/statement/value-normalized/\"]\n",
    "\n",
    "for line in res:\n",
    "    for prefix in prefixes:\n",
    "        f.write(prefix+line[0].split(\"/\")[-1]+\"\\t\"+line[1].replace(\"\\\\\",\"\").replace('\"',\"\")+\"\\t\"+line[2].replace(\"\\\\\",\"\").replace('\"',\"\")+\"\\t\"+line[3].replace(\"\\\\\",\"\").replace('\"',\"\")+\"\\t\")\n",
    "        if (line[0] in dic_prop):\n",
    "            f.write(\",\".join(dic_prop[line[0]][0])+\"\\t\"+\",\".join(dic_prop[line[0]][1]))\n",
    "        else:\n",
    "            f.write(\" \\t \")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b81931",
   "metadata": {},
   "source": [
    "# Classes\n",
    "\n",
    "## We first retrieve the property data so we can launch the second part without the first and obtain the classes that we need to retrieve from the Domain and Range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fe954a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wikidata_P_describe.txt\", sep=\"\\t\", header=None, names=[\"prop\", \"label\", \"description\", \"wikibase\", \"domain\", \"range\"])\n",
    "\n",
    "classes_to_retrieve = set()\n",
    "df = df.replace(np.nan,\"\")\n",
    "for i in range(len(df)):\n",
    "    domain, rang = df.iloc[i][[\"domain\", \"range\"]]\n",
    "    classes_to_retrieve = classes_to_retrieve.union(set(domain.split(\",\")))\n",
    "    classes_to_retrieve = classes_to_retrieve.union(set(rang.split(\",\")))\n",
    "    \n",
    "classes_to_retrieve.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcc30e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will transfrom a list of URI from their full length \"http://wikidata/....\" to the short version \"wd:\" \n",
    "def full_to_short(list_classes, short):\n",
    "    res = \"\"\n",
    "    for c in list_classes:\n",
    "        res += \" \"+short+c.split(\"/\")[-1]+\" \"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e7911",
   "metadata": {},
   "source": [
    "## Label and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59a6f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<Response [200]>\n",
      "250\n",
      "<Response [200]>\n",
      "500\n",
      "<Response [200]>\n",
      "750\n",
      "<Response [200]>\n",
      "1000\n",
      "<Response [200]>\n",
      "1250\n",
      "<Response [200]>\n",
      "1500\n",
      "<Response [200]>\n",
      "1750\n",
      "<Response [200]>\n",
      "2000\n",
      "<Response [200]>\n",
      "2250\n",
      "<Response [200]>\n",
      "2500\n",
      "<Response [200]>\n",
      "2750\n",
      "<Response [200]>\n",
      "3000\n",
      "<Response [200]>\n",
      "3250\n",
      "<Response [200]>\n",
      "3500\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://query.wikidata.org/sparql'\n",
    "res_classes = []\n",
    "step = 250\n",
    "\n",
    "list_classes_to_retrieve = list(classes_to_retrieve)\n",
    "\n",
    "for i in range(0,len(list_classes_to_retrieve), step):\n",
    "    print(i)\n",
    "    query = \"\"\"\n",
    "    \n",
    "    SELECT DISTINCT ?class ?label ?description\n",
    "    WHERE {\n",
    "      VALUES ?class { \"\"\"+full_to_short(list_classes_to_retrieve[i:i+step], \"wd:\")+\"\"\" } \n",
    "      ?class rdfs:label ?label.\n",
    "      OPTIONAL{?class schema:description ?description.\n",
    "          FILTER(LANG(?description) = \"en\")}\n",
    "      FILTER(LANG(?label) = \"en\")\n",
    "    }  LIMIT 10000\"\"\"\n",
    "    \n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    print(r)\n",
    "    data = r.json()\n",
    "    if len(data[\"results\"][\"bindings\"]) > 1:\n",
    "        for line in data[\"results\"][\"bindings\"]:\n",
    "            prop = line[\"class\"][\"value\"]\n",
    "            label = line[\"label\"][\"value\"]\n",
    "            description = \"\"\n",
    "            if \"description\" in line:\n",
    "                description = line[\"description\"][\"value\"]\n",
    "            res_classes.append([prop, label, description])\n",
    "    else:\n",
    "        print(\"Got nothing\")\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b0114",
   "metadata": {},
   "source": [
    "## Write the final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df6ff464",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"wikidata_C_describe.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for line in res_classes:\n",
    "    f.write(\"\\t\".join(line)+\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
