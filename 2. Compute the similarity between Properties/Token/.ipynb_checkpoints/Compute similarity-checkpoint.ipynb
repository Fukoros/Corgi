{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54bbba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, BASIC\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "import sys\n",
    "from multiprocessing import Process, Manager, Queue\n",
    "import multiprocessing\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\"</s>\")\n",
    "\n",
    "def empty_vector(x):\n",
    "    for i in x:\n",
    "        if sum(i.vector) == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def connected_to_natural(x):\n",
    "    res = \"\"\n",
    "    len_x = len(x)\n",
    "    for i, carac in enumerate(x):\n",
    "        if (i >= 1) and (i<(len_x-1)) and (ord(carac)>=ord(\"A\")) and (ord(carac)<=ord(\"Z\")) and (ord(x[i+1])>=ord(\"a\")) and (ord(x[i+1])<=ord(\"z\")):\n",
    "            res+=\" \"+carac\n",
    "        else:\n",
    "            res+=carac\n",
    "    return res\n",
    "\n",
    "def preprocess(text):\n",
    "    text = connected_to_natural(text)\n",
    "    return [word for word in gensim.utils.simple_preprocess(text,min_len=1,max_len=50) if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53044969",
   "metadata": {},
   "source": [
    "# Retrieve the server info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ff31677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open('./../../config.json')\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "  \n",
    "url_server = data[\"ServerInfo\"][\"url\"]\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349b367",
   "metadata": {},
   "source": [
    "# Retrieve the data of all the properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cedcea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "sparql = SPARQLWrapper(url_server)\n",
    "sparql.setReturnFormat('json')\n",
    "sparql.method = 'GET'\n",
    "\n",
    "data_props = {}\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?label ?comment ?ontology\n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Property.\n",
    "    ?prop <http://graph/origin>  ?ontology.\n",
    "    ?prop rdfs:label ?label.\n",
    "    OPTIONAL{?prop rdfs:description ?comment}.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    \n",
    "    data_props[r[\"prop\"][\"value\"]] = {\"label\":r[\"label\"][\"value\"], \"comment\":\"\", \"domain\":set(), \"range\":set(), \"onto\": r[\"ontology\"][\"value\"]}\n",
    "    if \"comment\" in r:\n",
    "        data_props[r[\"prop\"][\"value\"]][\"comment\"] = r[\"comment\"][\"value\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4790e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?domain\n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Property.\n",
    "    ?prop rdfs:label ?label.\n",
    "    ?prop rdfs:domain ?domain.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    data_props[r[\"prop\"][\"value\"]][\"domain\"].add(r[\"domain\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3216be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?range\n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Property.\n",
    "    ?prop rdfs:label ?label.\n",
    "    ?prop rdfs:range  ?range.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    data_props[r[\"prop\"][\"value\"]][\"range\"].add(r[\"range\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ab538",
   "metadata": {},
   "source": [
    "# Retrieve the data of the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fdd10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "sparql = SPARQLWrapper(url_server)\n",
    "sparql.setReturnFormat('json')\n",
    "sparql.method = 'GET'\n",
    "\n",
    "classes = {}\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?label ?comment \n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Class.\n",
    "    ?prop rdfs:label ?label.\n",
    "    OPTIONAL{?prop rdfs:description ?comment}.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    \n",
    "    classes[r[\"prop\"][\"value\"]] = {\"label\":r[\"label\"][\"value\"], \"comment\":\"\"}\n",
    "    if \"comment\" in r:\n",
    "        classes[r[\"prop\"][\"value\"]][\"comment\"] = r[\"comment\"][\"value\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189009",
   "metadata": {},
   "source": [
    "# Compute the similarity between the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "843118d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = pd.DataFrame.from_dict(classes, orient=\"index\")\n",
    "\n",
    "df_classes[\"label doc\"] = df_classes[\"label\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_classes[\"comment doc\"] = df_classes[\"comment\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_classes[\"comment not empty\"] = df_classes[\"comment doc\"].map(lambda x: len(x) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bda054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = df_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a29c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_classes(name, queue, dict_shared_sim_classes, df_classes, total_length, counter, next_print):\n",
    "\n",
    "    print(f\"Process n°{name} : Launched\", flush=True)\n",
    "\n",
    "    dict_local_sim_classes = {}\n",
    "\n",
    "    while not queue.empty():\n",
    "\n",
    "        index, prop_1 = queue.get()\n",
    "\n",
    "        for prop_2 in df_classes[index:].index:\n",
    "\n",
    "            sim = 0\n",
    "            nb_sim = 0\n",
    "\n",
    "            sim += df_classes[\"label doc\"].loc[prop_1].similarity(df_classes[\"label doc\"].loc[prop_2])\n",
    "            nb_sim += 1\n",
    "\n",
    "            if df_classes[\"comment not empty\"].loc[prop_1] and df_classes[\"comment not empty\"].loc[prop_2]:\n",
    "                sim += df_classes[\"comment doc\"].loc[prop_1].similarity(df_classes[\"comment doc\"].loc[prop_2])\n",
    "                nb_sim += 1\n",
    "\n",
    "            sim /= nb_sim\n",
    "\n",
    "            dict_local_sim_classes[(prop_1, prop_2)] = sim\n",
    "            dict_local_sim_classes[(prop_2, prop_1)] = sim\n",
    "\n",
    "        ## Every 0.5% we will print the advancement\n",
    "        counter.value += 1\n",
    "        if (counter.value/total_length > next_print.value):\n",
    "            print(next_print.value*100, \"%\", flush=True)\n",
    "            next_print.value+=0.5\n",
    "\n",
    "    dict_shared_sim_classes.update(dict_local_sim_classes)\n",
    "    \n",
    "    print(f\"Process n°{name} : Finished\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae46163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "dict_sim_classes = {}\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "for i, prop_1 in enumerate(df_classes.index):\n",
    "    q.put((i,prop_1))\n",
    "    \n",
    "size_queue = q.qsize()\n",
    "\n",
    "with Manager() as manager:\n",
    "\n",
    "    processes_to_create = multiprocessing.cpu_count()-1\n",
    "    processes = list()\n",
    "    \n",
    "    dict_shared_sim_classes = manager.dict()\n",
    "    counter = manager.Value(\"counter\",0)\n",
    "    next_print = manager.Value(\"next_print\",0)\n",
    "    \n",
    "    for name in range(processes_to_create):\n",
    "#         x = Process(target=test_p, args=(name,counter))  \n",
    "#         processes.append(x)\n",
    "#         x.start()\n",
    "        x = Process(target=compute_similarity_classes, args=(name, q, dict_shared_sim_classes, df_classes, size_queue, counter, next_print))\n",
    "        processes.append(x)\n",
    "        x.start()\n",
    "        \n",
    "    for index, process in enumerate(processes):\n",
    "        process.join()\n",
    "\n",
    "    print(counter)\n",
    "    \n",
    "    dict_sim_classes = dict(dict_shared_sim_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474331d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(dict_sim_classes, orient=\"index\").to_csv(\"sim_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def compute_similarity_classes( index, dict_shared_sim_classes, df_classes):\n",
    "        \n",
    "#     prop_1 = df_classes.index[index]\n",
    "\n",
    "#     for prop_2 in df_classes[index:]:\n",
    "\n",
    "#         sim = 0\n",
    "#         nb_sim = 0\n",
    "\n",
    "#         sim += df_classes[\"label doc\"].loc[prop_1].similarity(df_classes[\"label doc\"].loc[prop_2])\n",
    "#         nb_sim += 1\n",
    "\n",
    "#         if df_classes[\"comment not empty\"].loc[prop_1] and df_classes[\"comment not empty\"].loc[prop_2]:\n",
    "#             sim += df_classes[\"comment doc\"].loc[prop_1].similarity(df_classes[\"comment doc\"].loc[prop_2])\n",
    "#             nb_sim += 1\n",
    "\n",
    "#         sim /= nb_sim   \n",
    "\n",
    "#         dict_shared_sim_classes[(prop_1, prop_2)] = sim\n",
    "#         dict_shared_sim_classes[(prop_2, prop_1)] = sim\n",
    "\n",
    "# dict_sim_classes = {}\n",
    "\n",
    "# # q = Queue()\n",
    "\n",
    "# # for i, prop_1 in enumerate(df_classes.index):\n",
    "# #     q.put((i,prop_1))\n",
    "    \n",
    "# # size_queue = q.qsize()\n",
    "            \n",
    "\n",
    "# with Manager() as manager:\n",
    "    \n",
    "#     dict_shared_sim_classes = manager.dict()\n",
    "    \n",
    "#     PROCESSES = 2\n",
    "#     with multiprocessing.Pool(PROCESSES) as pool:\n",
    "#         params = [(index,dict_shared_sim_classes, df_classes) for index in range(len(df_classes))]\n",
    "#         print(len(params))\n",
    "#         results = [pool.apply_async(compute_similarity_classes, p) for p in params]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d392e",
   "metadata": {},
   "source": [
    "# Compute the sim between properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c257c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://wikidata.org                                                   60174\n",
       "http://schema.org/                                                      803\n",
       "http://dbpedia.org/ontology/                                            561\n",
       "https://www.ica.org/standards/RiC/ontology                              485\n",
       "https://w3id.org/arco/ontology/context-description                      337\n",
       "                                                                      ...  \n",
       "http://securitytoolbox.appspot.com/securityMain                           1\n",
       "http://mex.aksw.org/mex-perf                                              1\n",
       "http://vocab.data.gov/def/fea                                             1\n",
       "https://w3id.org/seas/StatisticsOntology                                  1\n",
       "http://www.semanticweb.org/ontologies/2008/11/OntologySecurity.owl        1\n",
       "Name: onto, Length: 619, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_props = pd.DataFrame.from_dict(data_props, orient=\"index\")\n",
    "\n",
    "df_props[\"onto\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4931c902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78890"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "dict_sim_props = {}\n",
    "\n",
    "df_props = pd.DataFrame.from_dict(data_props, orient=\"index\")\n",
    "\n",
    "df_props[\"label doc\"] = df_props[\"label\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_props[\"comment doc\"] = df_props[\"comment\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_props[\"comment not empty\"] = df_props[\"comment doc\"].map(lambda x: len(x) != 0)\n",
    "df_props[\"domain not empty\"] = df_props[\"domain\"].map(lambda x: len(x) != 0)\n",
    "df_props[\"range not empty\"] = df_props[\"range\"].map(lambda x: len(x) != 0)\n",
    "\n",
    "len(df_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052b106",
   "metadata": {},
   "source": [
    "For wikidata we have to use x6 properties because we have direct/statement/.... <br>\n",
    "Thus we can reduce the number of prop for the wikidata onto and thus be faster (hopefully)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac3ba517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28745"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_props = df_props[df_props[[\"onto\"]].apply(lambda x: x[\"onto\"] != \"http://wikidata.org\" or x.name[:30]==\"http://www.wikidata.org/prop/P\", axis=1)]\n",
    "len(df_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca146de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://wikidata.org                                                   10029\n",
       "http://schema.org/                                                      803\n",
       "http://dbpedia.org/ontology/                                            561\n",
       "https://www.ica.org/standards/RiC/ontology                              485\n",
       "https://w3id.org/arco/ontology/context-description                      337\n",
       "                                                                      ...  \n",
       "http://securitytoolbox.appspot.com/securityMain                           1\n",
       "http://mex.aksw.org/mex-perf                                              1\n",
       "http://vocab.data.gov/def/fea                                             1\n",
       "https://w3id.org/seas/StatisticsOntology                                  1\n",
       "http://www.semanticweb.org/ontologies/2008/11/OntologySecurity.owl        1\n",
       "Name: onto, Length: 619, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_props[\"onto\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_property(name, queue, dict_shared_sim_properties, df_props_1, df_props_2):\n",
    "    print(f\"Process n°{name} : Launched\", flush=True)\n",
    "\n",
    "    dict_local_sim_properties = {}\n",
    "\n",
    "    while not queue.empty():\n",
    "\n",
    "        index, prop_1 = queue.get()\n",
    "\n",
    "        for prop_2 in df_props_2.index:\n",
    "            sim = 0\n",
    "            nb_sim = 0\n",
    "\n",
    "            sim += df_props_1[\"label doc\"].loc[prop_1].similarity(df_props_2[\"label doc\"].loc[prop_2])\n",
    "            nb_sim += 1\n",
    "\n",
    "            if df_props_1[\"comment not empty\"].loc[prop_1] and df_props_2[\"comment not empty\"].loc[prop_2]:\n",
    "                sim += df_props_1[\"comment doc\"].loc[prop_1].similarity(df_props_2[\"comment doc\"].loc[prop_2])\n",
    "                nb_sim += 1\n",
    "\n",
    "            if df_props_1[\"domain not empty\"].loc[prop_1] and df_props_2[\"domain not empty\"].loc[prop_2]:\n",
    "                domain_1, domain_2 = df_props_1[\"domain\"].loc[prop_1], df_props_2[\"domain\"].loc[prop_2]\n",
    "                sim_domain = -1\n",
    "                for d_1 in domain_1:\n",
    "                    for d_2 in domain_2:\n",
    "                        if (d_1, d_2) in dict_sim_classes:\n",
    "                            sim_domain = max(sim_domain, dict_sim_classes[(d_1, d_2)])\n",
    "                if sim_domain != -1:\n",
    "                    sim += sim_domain\n",
    "                    nb_sim += 1\n",
    "\n",
    "\n",
    "            if df_props_1[\"range not empty\"].loc[prop_1] and df_props_2[\"range not empty\"].loc[prop_2]:\n",
    "                range_1, range_2 = df_props_1[\"range\"].loc[prop_1], df_props_2[\"range\"].loc[prop_2]\n",
    "                sim_range = -1\n",
    "                for r_1 in range_1:\n",
    "                    for r_2 in range_2:\n",
    "                        if (r_1, r_2) in dict_sim_classes:\n",
    "                            sim_range = max(sim_range, dict_sim_classes[(r_1, r_2)])\n",
    "                if sim_domain != -1:\n",
    "                    sim += sim_range\n",
    "                    nb_sim += 1\n",
    "\n",
    "            sim/=nb_sim\n",
    "\n",
    "            dict_local_sim_properties[(prop_1, prop_2)] = sim\n",
    "\n",
    "    dict_shared_sim_properties.update(dict_local_sim_properties)\n",
    "    \n",
    "    print(f\"Process n°{name} : Finished\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe9bda2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on wikidata & dbpedia with 10029x3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:19: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "<timed exec>:23: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3578.836715698242\n",
      "Working on wikidata & schema with 10029x1448\n",
      "1670.19851064682\n",
      "Working on wikidata & foaf with 10029x54\n",
      "74.8915364742279\n",
      "Working on wikidata & owl with 10029x44\n",
      "60.0958411693573\n",
      "Working on wikidata & w3 with 10029x9\n",
      "12.567718744277954\n",
      "Working on wikidata & rdf with 10029x7\n",
      "9.622103452682495\n",
      "Working on dbpedia & schema with 3136x1448\n",
      "478.11180090904236\n",
      "Working on dbpedia & foaf with 3136x54\n",
      "20.74883508682251\n",
      "Working on dbpedia & owl with 3136x44\n",
      "16.98633885383606\n",
      "Working on dbpedia & w3 with 3136x9\n",
      "3.9177470207214355\n",
      "Working on dbpedia & rdf with 3136x7\n",
      "2.7023086547851562\n",
      "Working on schema & foaf with 1448x54\n",
      "13.512605667114258\n",
      "Working on schema & owl with 1448x44\n",
      "8.603918552398682\n",
      "Working on schema & w3 with 1448x9\n",
      "1.7357933521270752\n",
      "Working on schema & rdf with 1448x7\n",
      "1.3591079711914062\n",
      "Working on foaf & owl with 54x44\n",
      "0.39124321937561035\n",
      "Working on foaf & w3 with 54x9\n",
      "0.08173680305480957\n",
      "Working on foaf & rdf with 54x7\n",
      "0.06370234489440918\n",
      "Working on owl & w3 with 44x9\n",
      "0.07028675079345703\n",
      "Working on owl & rdf with 44x7\n",
      "0.05429410934448242\n",
      "Working on w3 & rdf with 9x7\n",
      "0.011148691177368164\n",
      "Wall time: 1h 39min 14s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "ontos = list(df_props[\"onto\"].value_counts().index)\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "with Manager() as manager:\n",
    "\n",
    "    processes_to_create = multiprocessing.cpu_count()-1\n",
    "    dict_shared_sim_properties = manager.dict()\n",
    "    \n",
    "    for i, onto_1 in enumerate(ontos[:2]):\n",
    "        df_props_1 = df_props[df_props[\"onto\"]==onto_1]\n",
    "\n",
    "        for onto_2 in ontos[i+1:2]:\n",
    "            df_props_2 = df_props[df_props[\"onto\"]==onto_2]\n",
    "\n",
    "            print(f\"Working on {onto_1} & {onto_2} with {len(df_props_1)}x{len(df_props_2)}\")\n",
    "            start = time.time()\n",
    "\n",
    "            for i, prop_1 in enumerate(df_props_1.index):\n",
    "                q.put((i,prop_1))\n",
    "\n",
    "            processes = list()\n",
    "\n",
    "            for name in range(processes_to_create):\n",
    "                x = Process(target=compute_similarity_property, args=(name, q, dict_shared_sim_properties, df_props_1, df_props_2))\n",
    "                processes.append(x)\n",
    "                x.start()\n",
    "\n",
    "            for index, process in enumerate(processes):\n",
    "                process.join()\n",
    "\n",
    "            end = time.time()\n",
    "            print(end - start)\n",
    "            \n",
    "        print(f\"Finished with {onto_1}\")\n",
    "        \n",
    "    print(\"Finished computation -> Copy the dictionary\")    \n",
    "    dict_sim_properties = dict(dict_shared_sim_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20666804",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"similarity.ttl\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Finished Copy -> Writing result\")    \n",
    "for key in dict_sim_props:\n",
    "    f.write(f\"<{key[0]}> <http://graph/simComputed> <{key[1]}>.\\n\")\n",
    "    f.write(f\"<< <{key[0]}> <http://graph/simComputed> <{key[1]}> >> <http://graph/sim> {dict_sim_props[key]} .\\n\")\n",
    "    \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
