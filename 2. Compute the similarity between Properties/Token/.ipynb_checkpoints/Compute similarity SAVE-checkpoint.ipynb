{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54bbba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from SPARQLWrapper import SPARQLWrapper, BASIC\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\"</s>\")\n",
    "\n",
    "def empty_vector(x):\n",
    "    for i in x:\n",
    "        if sum(i.vector) == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def connected_to_natural(x):\n",
    "    res = \"\"\n",
    "    len_x = len(x)\n",
    "    for i, carac in enumerate(x):\n",
    "        if (i >= 1) and (i<(len_x-1)) and (ord(carac)>=ord(\"A\")) and (ord(carac)<=ord(\"Z\")) and (ord(x[i+1])>=ord(\"a\")) and (ord(x[i+1])<=ord(\"z\")):\n",
    "            res+=\" \"+carac\n",
    "        else:\n",
    "            res+=carac\n",
    "    return res\n",
    "\n",
    "def preprocess(text):\n",
    "    text = connected_to_natural(text)\n",
    "    return [word for word in gensim.utils.simple_preprocess(text,min_len=1,max_len=50) if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349b367",
   "metadata": {},
   "source": [
    "# Retrieve the data of all the properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cedcea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sparql = SPARQLWrapper(\"http://Thibaut:7200/repositories/Catalog\", agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36')\n",
    "sparql.setReturnFormat('json')\n",
    "sparql.method = 'GET'\n",
    "\n",
    "data_props = {}\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "SELECT ?prop ?label ?comment ?ontology\n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Property.\n",
    "    ?prop <http://graph/origin>  ?ontology.\n",
    "    ?prop rdfs:label ?label.\n",
    "    OPTIONAL{?prop rdfs:comment ?comment}.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    \n",
    "    data_props[r[\"prop\"][\"value\"]] = {\"label\":r[\"label\"][\"value\"], \"comment\":\"\", \"domain\":set(), \"range\":set(), \"onto\": r[\"ontology\"][\"value\"]}\n",
    "    if \"comment\" in r:\n",
    "        data_props[r[\"prop\"][\"value\"]][\"comment\"] = r[\"comment\"][\"value\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4790e2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?domain\n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Property.\n",
    "    ?prop rdfs:label ?label.\n",
    "    ?prop rdfs:domain ?domain.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    data_props[r[\"prop\"][\"value\"]][\"domain\"].add(r[\"domain\"][\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d3216be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?range\n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Property.\n",
    "    ?prop rdfs:label ?label.\n",
    "    ?prop rdfs:range  ?range.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    data_props[r[\"prop\"][\"value\"]][\"range\"].add(r[\"range\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ab538",
   "metadata": {},
   "source": [
    "# Retrieve the data of the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fdd10e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sparql = SPARQLWrapper(\"http://Thibaut:7200/repositories/Catalog\", agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36')\n",
    "sparql.setReturnFormat('json')\n",
    "sparql.method = 'GET'\n",
    "\n",
    "classes = {}\n",
    "\n",
    "q = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "SELECT ?prop ?label ?comment \n",
    "WHERE {\n",
    "    ?prop rdf:type rdf:Class.\n",
    "    ?prop rdfs:label ?label.\n",
    "    OPTIONAL{?prop rdfs:comment ?comment}.\n",
    "}\"\"\"\n",
    "\n",
    "sparql.setQuery(q)\n",
    "response = sparql.queryAndConvert()\n",
    "for r in response[\"results\"][\"bindings\"]:\n",
    "    \n",
    "    classes[r[\"prop\"][\"value\"]] = {\"label\":r[\"label\"][\"value\"], \"comment\":\"\"}\n",
    "    if \"comment\" in r:\n",
    "        classes[r[\"prop\"][\"value\"]][\"comment\"] = r[\"comment\"][\"value\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189009",
   "metadata": {},
   "source": [
    "# Compute the sim between the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "843118d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = pd.DataFrame.from_dict(classes, orient=\"index\")\n",
    "\n",
    "df_classes[\"label doc\"] = df_classes[\"label\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_classes[\"comment doc\"] = df_classes[\"comment\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_classes[\"comment not empty\"] = df_classes[\"comment doc\"].map(lambda x: len(x) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc2a9828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33851"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc965e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<timed exec>:9: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "102it [02:40,  1.49s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_sim_classes = {}\n",
    "\n",
    "for i, prop_1 in tqdm(enumerate(df_classes.index)):\n",
    "    \n",
    "    for prop_2 in df_classes.index[i:]:\n",
    "        sim = 0\n",
    "        nb_sim = 0\n",
    "        \n",
    "        sim += df_classes[\"label doc\"].loc[prop_1].similarity(df_classes[\"label doc\"].loc[prop_2])\n",
    "        nb_sim += 1\n",
    "        \n",
    "        if df_classes[\"comment not empty\"].loc[prop_1] and df_classes[\"comment not empty\"].loc[prop_2]:\n",
    "            sim += df_classes[\"comment doc\"].loc[prop_1].similarity(df_classes[\"comment doc\"].loc[prop_2])\n",
    "            nb_sim += 1\n",
    "            \n",
    "        sim/= nb_sim   \n",
    "        \n",
    "        dict_sim_classes[(prop_1, prop_2)] = sim\n",
    "        dict_sim_classes[(prop_2, prop_1)] = sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5d392e",
   "metadata": {},
   "source": [
    "# Compute the sim between properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c257c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://wikidata.org                                                   60174\n",
       "http://schema.org/                                                      803\n",
       "http://dbpedia.org/ontology/                                            561\n",
       "https://www.ica.org/standards/RiC/ontology                              485\n",
       "https://w3id.org/arco/ontology/context-description                      337\n",
       "                                                                      ...  \n",
       "http://securitytoolbox.appspot.com/securityMain                           1\n",
       "http://mex.aksw.org/mex-perf                                              1\n",
       "http://vocab.data.gov/def/fea                                             1\n",
       "https://w3id.org/seas/StatisticsOntology                                  1\n",
       "http://www.semanticweb.org/ontologies/2008/11/OntologySecurity.owl        1\n",
       "Name: onto, Length: 619, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_props = pd.DataFrame.from_dict(data_props, orient=\"index\")\n",
    "\n",
    "df_props[\"onto\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4931c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78890"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dict_sim_props = {}\n",
    "\n",
    "df_props = pd.DataFrame.from_dict(data_props, orient=\"index\")\n",
    "\n",
    "df_props[\"label doc\"] = df_props[\"label\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_props[\"comment doc\"] = df_props[\"comment\"].map(lambda x: Doc(nlp.vocab, words=preprocess(x)))\n",
    "df_props[\"comment not empty\"] = df_props[\"comment doc\"].map(lambda x: len(x) != 0)\n",
    "df_props[\"domain not empty\"] = df_props[\"domain\"].map(lambda x: len(x) != 0)\n",
    "df_props[\"range not empty\"] = df_props[\"range\"].map(lambda x: len(x) != 0)\n",
    "\n",
    "len(df_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052b106",
   "metadata": {},
   "source": [
    "For wikidata we have to use x6 properties because we have direct/statement/.... <br>\n",
    "Thus we can reduce the number of prop for the wikidata onto and thus be faster (hopefully)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3ba517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_props = df_props[df_props[[\"onto\"]].apply(lambda x: x[\"onto\"] != \"wikidata\" or x.name[:30]==\"http://www.wikidata.org/prop/p\", axis=1)]\n",
    "len(df_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372b264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ontos = list(df_props[\"onto\"].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe9bda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on wikidata & dbpedia with 10029x3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:19: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "<timed exec>:23: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3578.836715698242\n",
      "Working on wikidata & schema with 10029x1448\n",
      "1670.19851064682\n",
      "Working on wikidata & foaf with 10029x54\n",
      "74.8915364742279\n",
      "Working on wikidata & owl with 10029x44\n",
      "60.0958411693573\n",
      "Working on wikidata & w3 with 10029x9\n",
      "12.567718744277954\n",
      "Working on wikidata & rdf with 10029x7\n",
      "9.622103452682495\n",
      "Working on dbpedia & schema with 3136x1448\n",
      "478.11180090904236\n",
      "Working on dbpedia & foaf with 3136x54\n",
      "20.74883508682251\n",
      "Working on dbpedia & owl with 3136x44\n",
      "16.98633885383606\n",
      "Working on dbpedia & w3 with 3136x9\n",
      "3.9177470207214355\n",
      "Working on dbpedia & rdf with 3136x7\n",
      "2.7023086547851562\n",
      "Working on schema & foaf with 1448x54\n",
      "13.512605667114258\n",
      "Working on schema & owl with 1448x44\n",
      "8.603918552398682\n",
      "Working on schema & w3 with 1448x9\n",
      "1.7357933521270752\n",
      "Working on schema & rdf with 1448x7\n",
      "1.3591079711914062\n",
      "Working on foaf & owl with 54x44\n",
      "0.39124321937561035\n",
      "Working on foaf & w3 with 54x9\n",
      "0.08173680305480957\n",
      "Working on foaf & rdf with 54x7\n",
      "0.06370234489440918\n",
      "Working on owl & w3 with 44x9\n",
      "0.07028675079345703\n",
      "Working on owl & rdf with 44x7\n",
      "0.05429410934448242\n",
      "Working on w3 & rdf with 9x7\n",
      "0.011148691177368164\n",
      "Wall time: 1h 39min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ontos = list(df_props[\"onto\"].value_counts().index)\n",
    "\n",
    "for i, onto_1 in enumerate(ontos):\n",
    "    df_props_1 = df_props[df_props[\"onto\"]==onto_1]\n",
    "    \n",
    "    for onto_2 in ontos[i+1:]:\n",
    "        df_props_2 = df_props[df_props[\"onto\"]==onto_2]\n",
    "        \n",
    "        print(f\"Working on {onto_1} & {onto_2} with {len(df_props_1)}x{len(df_props_2)}\")\n",
    "        start = time.time()\n",
    "        \n",
    "\n",
    "        for prop_1 in df_props_1.index:\n",
    "    \n",
    "            for prop_2 in df_props_2.index:\n",
    "                sim = 0\n",
    "                nb_sim = 0\n",
    "                \n",
    "                sim += df_props_1[\"label doc\"].loc[prop_1].similarity(df_props_2[\"label doc\"].loc[prop_2])\n",
    "                nb_sim += 1\n",
    "                \n",
    "                if df_props_1[\"comment not empty\"].loc[prop_1] and df_props_2[\"comment not empty\"].loc[prop_2]:\n",
    "                    sim += df_props_1[\"comment doc\"].loc[prop_1].similarity(df_props_2[\"comment doc\"].loc[prop_2])\n",
    "                    nb_sim += 1\n",
    "                    \n",
    "                if df_props_1[\"domain not empty\"].loc[prop_1] and df_props_2[\"domain not empty\"].loc[prop_2]:\n",
    "                    domain_1, domain_2 = df_props_1[\"domain\"].loc[prop_1], df_props_2[\"domain\"].loc[prop_2]\n",
    "                    sim_domain = -1\n",
    "                    for d_1 in domain_1:\n",
    "                        for d_2 in domain_2:\n",
    "                            # Because DBPEDIA uses property as domain (WTF)\n",
    "                            if (d_1, d_2) in dict_sim_classes:\n",
    "                                sim_domain = max(sim_domain, dict_sim_classes[(d_1, d_2)])\n",
    "                    if sim_domain != -1:\n",
    "                        sim += sim_domain\n",
    "                        nb_sim += 1\n",
    "                    \n",
    "                \n",
    "                if df_props_1[\"range not empty\"].loc[prop_1] and df_props_2[\"range not empty\"].loc[prop_2]:\n",
    "                    range_1, range_2 = df_props_1[\"range\"].loc[prop_1], df_props_2[\"range\"].loc[prop_2]\n",
    "                    sim_range = -1\n",
    "                    for r_1 in range_1:\n",
    "                        for r_2 in range_2:\n",
    "                            if (r_1, r_2) in dict_sim_classes:\n",
    "                                sim_range = max(sim_range, dict_sim_classes[(r_1, r_2)])\n",
    "                    if sim_domain != -1:\n",
    "                        sim += sim_range\n",
    "                        nb_sim += 1\n",
    "                \n",
    "                sim/=nb_sim\n",
    "                \n",
    "                dict_sim_props[(prop_1, prop_2)] = sim\n",
    "        \n",
    "        end = time.time()\n",
    "        print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20666804",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"similarity.ttl\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for key in dict_sim_props:\n",
    "    f.write(f\"<{key[0]}> <http://graph/simComputed> <{key[1]}>.\\n\")\n",
    "    f.write(f\"<< <{key[0]}> <http://graph/simComputed> <{key[1]}> >> <http://graph/sim> {dict_sim_props[key]} .\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e363d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
